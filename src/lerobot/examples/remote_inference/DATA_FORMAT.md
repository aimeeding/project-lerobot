# LeRobot è¿œç¨‹æ¨ç†æ•°æ®æ ¼å¼è¯¦è§£

## ğŸ“‹ æ¦‚è¿°

**æ˜¯çš„ï¼Œå®¢æˆ·ç«¯å’ŒæœåŠ¡å™¨ç«¯ä½¿ç”¨çš„æ˜¯LeRobotæ ‡å‡†æ ¼å¼ï¼**

LeRobotå®šä¹‰äº†ä¸€å¥—æ ‡å‡†çš„é”®åçº¦å®šæ¥æ ‡è¯†è§‚æµ‹å’ŒåŠ¨ä½œæ•°æ®ã€‚è¿™ç¡®ä¿äº†ç­–ç•¥æ¨¡å‹èƒ½å¤Ÿæ­£ç¡®ç†è§£è¾“å…¥è¾“å‡ºã€‚

## ğŸ”‘ LeRobotæ ‡å‡†é”®å

åœ¨ `lerobot/common/constants.py` ä¸­å®šä¹‰ï¼š

```python
# è§‚æµ‹ç›¸å…³
OBS_STATE = "observation.state"              # æœºå™¨äººçŠ¶æ€ (å…³èŠ‚ä½ç½®ç­‰)
OBS_IMAGES = "observation.images"            # å¤šä¸ªç›¸æœºå›¾åƒ
OBS_IMAGE = "observation.image"              # å•ä¸ªç›¸æœºå›¾åƒ  
OBS_ENV_STATE = "observation.environment_state"  # ç¯å¢ƒçŠ¶æ€

# åŠ¨ä½œ
ACTION = "action"

# å…¶ä»–
REWARD = "next.reward"
```

## ğŸ“Š æ•°æ®æ ¼å¼è§„èŒƒ

### 1. Observation (è§‚æµ‹) æ ¼å¼

ç­–ç•¥çš„ `select_action()` æ–¹æ³•æœŸæœ›æ¥æ”¶ä»¥ä¸‹æ ¼å¼çš„å­—å…¸ï¼š

```python
observation = {
    # å¿…éœ€ï¼šæœºå™¨äººçŠ¶æ€ (å…³èŠ‚ä½ç½®ã€é€Ÿåº¦ç­‰)
    "observation.state": torch.Tensor,  # shape: (batch_size, state_dim)
    
    # å¯é€‰ï¼šå›¾åƒè§‚æµ‹ (å¦‚æœç­–ç•¥ä½¿ç”¨è§†è§‰)
    "observation.images": List[torch.Tensor],  # å¤šç›¸æœº
    # æˆ–
    "observation.image": torch.Tensor,  # å•ç›¸æœº
    
    # å¯é€‰ï¼šç¯å¢ƒçŠ¶æ€
    "observation.environment_state": torch.Tensor,  # shape: (batch_size, env_dim)
    
    # å¯é€‰ï¼šä»»åŠ¡æè¿° (ç”¨äºVLAæ¨¡å‹å¦‚SmolVLA)
    "task": List[str],  # shape: (batch_size,)
}
```

#### è¯¦ç»†è§„èŒƒ

**1.1 `observation.state` (æœºå™¨äººçŠ¶æ€)**
- **ç±»å‹**: `torch.Tensor`
- **å½¢çŠ¶**: `(batch_size, state_dim)`
- **æ•°æ®ç±»å‹**: `torch.float32`
- **å–å€¼èŒƒå›´**: é€šå¸¸æ˜¯å½’ä¸€åŒ–åçš„ [-1, 1] æˆ–åŸå§‹å€¼
- **å†…å®¹**: å…³èŠ‚ä½ç½®ã€é€Ÿåº¦ã€åŠ›çŸ©ç­‰

ä¾‹å­ï¼š
```python
# SO100æœºå™¨äººæœ‰6ä¸ªå…³èŠ‚
observation_state = torch.tensor([[0.1, 0.2, -0.3, 0.0, 0.5, 0.8]])  # (1, 6)
```

**1.2 `observation.images` (å¤šç›¸æœºå›¾åƒ)**
- **ç±»å‹**: `List[torch.Tensor]` æˆ– `torch.Tensor`
- **å½¢çŠ¶**: æ¯ä¸ªç›¸æœº `(batch_size, channels, height, width)`
- **æ•°æ®ç±»å‹**: `torch.float32`
- **å–å€¼èŒƒå›´**: [0.0, 1.0] (å½’ä¸€åŒ–å)
- **é€šé“é¡ºåº**: Channel-first (C, H, W)

ä¾‹å­ï¼š
```python
# 2ä¸ªç›¸æœºï¼Œ224x224 RGBå›¾åƒ
camera1 = torch.rand(1, 3, 224, 224)  # å€¼åœ¨[0,1]
camera2 = torch.rand(1, 3, 224, 224)
observation_images = [camera1, camera2]

# æˆ–è€…å †å æˆä¸€ä¸ªtensor
# observation_images = torch.stack([camera1, camera2], dim=1)  # (1, 2, 3, 224, 224)
```

**1.3 `task` (ä»»åŠ¡æè¿°) - ç”¨äºVLAæ¨¡å‹**
- **ç±»å‹**: `List[str]`
- **å½¢çŠ¶**: `(batch_size,)`
- **å†…å®¹**: è‡ªç„¶è¯­è¨€ä»»åŠ¡æè¿°

ä¾‹å­ï¼š
```python
task = ["Pick up the red cube"]  # batch_size=1
```

### 2. Action (åŠ¨ä½œ) æ ¼å¼

ç­–ç•¥çš„ `select_action()` è¿”å›ï¼š

```python
action = torch.Tensor  # shape: (batch_size, action_dim)
```

- **ç±»å‹**: `torch.Tensor`
- **å½¢çŠ¶**: `(batch_size, action_dim)`
- **æ•°æ®ç±»å‹**: `torch.float32`
- **å–å€¼èŒƒå›´**: å–å†³äºç­–ç•¥è¾“å‡ºï¼ˆå¯èƒ½å·²å½’ä¸€åŒ–ï¼‰

ä¾‹å­ï¼š
```python
# SO100æœºå™¨äºº6ä¸ªå…³èŠ‚çš„ç›®æ ‡ä½ç½®
action = torch.tensor([[0.2, 0.3, -0.1, 0.0, 0.6, 0.9]])  # (1, 6)
```

## ğŸ”„ ä»æœºå™¨äººæ ¼å¼è½¬æ¢åˆ°LeRobotæ ¼å¼

### æœºå™¨äººåŸå§‹æ ¼å¼

æœºå™¨äººçš„ `get_observation()` è¿”å›çš„æ ¼å¼ï¼š

```python
robot_observation = {
    # å…³èŠ‚ä½ç½® (æ¯ä¸ªå…³èŠ‚ä¸€ä¸ªé”®)
    "shoulder_pan.pos": 0.1,
    "shoulder_lift.pos": 0.2,
    "elbow_flex.pos": -0.3,
    "wrist_flex.pos": 0.0,
    "wrist_roll.pos": 0.5,
    "gripper.pos": 0.8,
    
    # ç›¸æœºå›¾åƒ (numpyæ•°ç»„ï¼ŒHWCæ ¼å¼ï¼Œuint8)
    "observation.images.top": np.array(...),  # shape: (480, 640, 3), dtype: uint8
    "observation.images.wrist": np.array(...),  # shape: (480, 640, 3), dtype: uint8
}
```

### è½¬æ¢è¿‡ç¨‹

```python
import torch
import numpy as np

def robot_obs_to_policy_input(robot_obs: dict, motor_names: list, device: str = "cuda") -> dict:
    """
    å°†æœºå™¨äººåŸå§‹è§‚æµ‹è½¬æ¢ä¸ºLeRobotç­–ç•¥è¾“å…¥æ ¼å¼
    
    Args:
        robot_obs: æœºå™¨äººget_observation()çš„è¾“å‡º
        motor_names: å…³èŠ‚åç§°åˆ—è¡¨ï¼ŒæŒ‰é¡ºåºæ’åˆ—
        device: torchè®¾å¤‡
    
    Returns:
        ç­–ç•¥è¾“å…¥å­—å…¸
    """
    policy_obs = {}
    
    # 1. æå–å…³èŠ‚çŠ¶æ€
    state_values = []
    for motor in motor_names:
        key = f"{motor}.pos"
        if key in robot_obs:
            state_values.append(robot_obs[key])
    
    state_tensor = torch.tensor([state_values], dtype=torch.float32, device=device)
    policy_obs["observation.state"] = state_tensor  # (1, n_motors)
    
    # 2. å¤„ç†å›¾åƒ
    image_keys = [k for k in robot_obs.keys() if k.startswith("observation.images.")]
    
    if image_keys:
        images = []
        for img_key in sorted(image_keys):  # æ’åºç¡®ä¿é¡ºåºä¸€è‡´
            img = robot_obs[img_key]  # numpy array, (H, W, C), uint8
            
            # è½¬æ¢ä¸ºtensor
            img_tensor = torch.from_numpy(img)  # (H, W, C)
            
            # é‡æ’ä¸ºchannel-first
            img_tensor = img_tensor.permute(2, 0, 1)  # (C, H, W)
            
            # è½¬æ¢ä¸ºfloat32å¹¶å½’ä¸€åŒ–åˆ°[0, 1]
            img_tensor = img_tensor.float() / 255.0
            
            # æ·»åŠ batchç»´åº¦
            img_tensor = img_tensor.unsqueeze(0).to(device)  # (1, C, H, W)
            
            images.append(img_tensor)
        
        policy_obs["observation.images"] = images
    
    return policy_obs

# ä½¿ç”¨ç¤ºä¾‹
motor_names = ["shoulder_pan", "shoulder_lift", "elbow_flex", 
               "wrist_flex", "wrist_roll", "gripper"]

robot_obs = robot.get_observation()
policy_input = robot_obs_to_policy_input(robot_obs, motor_names)

# ç°åœ¨å¯ä»¥ç›´æ¥ä¼ ç»™ç­–ç•¥
action = policy.select_action(policy_input)
```

## ğŸ“¡ ç½‘ç»œä¼ è¾“æ ¼å¼

### é—®é¢˜ï¼šTensoræ— æ³•ç›´æ¥åºåˆ—åŒ–

`torch.Tensor` å’Œ `numpy.ndarray` æ— æ³•ç›´æ¥é€šè¿‡ç½‘ç»œå‘é€ï¼Œéœ€è¦åºåˆ—åŒ–ã€‚

### è§£å†³æ–¹æ¡ˆ 1: PyTorchåºåˆ—åŒ–

```python
import torch
import io

def serialize_observation(obs: dict) -> bytes:
    """å°†LeRobotæ ¼å¼è§‚æµ‹åºåˆ—åŒ–ä¸ºbytes"""
    # å°†æ‰€æœ‰tensorç§»åˆ°CPU
    obs_cpu = {}
    for key, value in obs.items():
        if isinstance(value, torch.Tensor):
            obs_cpu[key] = value.cpu()
        elif isinstance(value, list) and len(value) > 0 and isinstance(value[0], torch.Tensor):
            obs_cpu[key] = [v.cpu() for v in value]
        else:
            obs_cpu[key] = value
    
    # ä½¿ç”¨torch.saveåºåˆ—åŒ–
    buffer = io.BytesIO()
    torch.save(obs_cpu, buffer)
    return buffer.getvalue()

def deserialize_observation(data: bytes, device: str = "cuda") -> dict:
    """ä»bytesååºåˆ—åŒ–è§‚æµ‹"""
    buffer = io.BytesIO(data)
    obs = torch.load(buffer, weights_only=True)
    
    # ç§»åŠ¨åˆ°ç›®æ ‡è®¾å¤‡
    for key, value in obs.items():
        if isinstance(value, torch.Tensor):
            obs[key] = value.to(device)
        elif isinstance(value, list) and len(value) > 0 and isinstance(value[0], torch.Tensor):
            obs[key] = [v.to(device) for v in value]
    
    return obs
```

### è§£å†³æ–¹æ¡ˆ 2: æ•°å€¼æ•°ç»„åºåˆ—åŒ– (æ›´å°)

```python
import numpy as np

def serialize_observation_compact(obs: dict) -> dict:
    """å°†è§‚æµ‹è½¬æ¢ä¸ºå¯JSONåºåˆ—åŒ–çš„æ ¼å¼"""
    serialized = {}
    
    for key, value in obs.items():
        if isinstance(value, torch.Tensor):
            # è½¬ä¸ºnumpyç„¶åç¼–ç 
            arr = value.cpu().numpy()
            serialized[key] = {
                "data": arr.tobytes(),
                "shape": arr.shape,
                "dtype": str(arr.dtype)
            }
        elif isinstance(value, list) and isinstance(value[0], torch.Tensor):
            serialized[key] = [
                {
                    "data": v.cpu().numpy().tobytes(),
                    "shape": v.shape,
                    "dtype": str(v.dtype)
                }
                for v in value
            ]
        else:
            serialized[key] = value
    
    return serialized

def deserialize_observation_compact(data: dict, device: str = "cuda") -> dict:
    """ä»ç´§å‡‘æ ¼å¼ååºåˆ—åŒ–"""
    obs = {}
    
    for key, value in data.items():
        if isinstance(value, dict) and "data" in value:
            # é‡å»ºnumpyæ•°ç»„
            arr = np.frombuffer(value["data"], dtype=value["dtype"])
            arr = arr.reshape(value["shape"])
            # è½¬ä¸ºtensor
            obs[key] = torch.from_numpy(arr).to(device)
        elif isinstance(value, list) and isinstance(value[0], dict):
            obs[key] = [
                torch.from_numpy(
                    np.frombuffer(v["data"], dtype=v["dtype"]).reshape(v["shape"])
                ).to(device)
                for v in value
            ]
        else:
            obs[key] = value
    
    return obs
```

## ğŸŒ å®Œæ•´çš„å®¢æˆ·ç«¯-æœåŠ¡å™¨æ•°æ®æµ

### å®¢æˆ·ç«¯ (æœ¬åœ°æœºå™¨äºº)

```python
# 1. ä»æœºå™¨äººè·å–åŸå§‹è§‚æµ‹
robot_obs = robot.get_observation()
# æ ¼å¼: {"motor1.pos": 0.1, "motor2.pos": 0.2, "observation.images.cam1": np.array(...)}

# 2. è½¬æ¢ä¸ºLeRobotæ ¼å¼
policy_obs = robot_obs_to_policy_input(robot_obs, motor_names)
# æ ¼å¼: {"observation.state": torch.Tensor, "observation.images": [torch.Tensor, ...]}

# 3. åºåˆ—åŒ–å‡†å¤‡å‘é€
obs_bytes = serialize_observation(policy_obs)
# æ ¼å¼: bytes

# 4. é€šè¿‡ç½‘ç»œå‘é€ (ZMQ/gRPC/HTTP)
request = {
    "command": "select_action",
    "observation": obs_bytes,
    "task": "Pick up the cube"  # å¯é€‰
}
socket.send(pickle.dumps(request))

# 5. æ¥æ”¶åŠ¨ä½œ
response = pickle.loads(socket.recv())
action_bytes = response["action"]

# 6. ååºåˆ—åŒ–åŠ¨ä½œ
action = deserialize_tensor(action_bytes)
# æ ¼å¼: torch.Tensor, shape: (1, action_dim)

# 7. è½¬æ¢å›æœºå™¨äººæ ¼å¼
action_dict = {}
for i, motor in enumerate(motor_names):
    action_dict[f"{motor}.pos"] = action[0, i].item()
# æ ¼å¼: {"motor1.pos": 0.15, "motor2.pos": 0.25, ...}

# 8. å‘é€ç»™æœºå™¨äºº
robot.send_action(action_dict)
```

### æœåŠ¡å™¨ (AutoDL GPU)

```python
# 1. æ¥æ”¶è¯·æ±‚
request = pickle.loads(socket.recv())

# 2. ååºåˆ—åŒ–è§‚æµ‹
obs_bytes = request["observation"]
policy_obs = deserialize_observation(obs_bytes, device="cuda")
# æ ¼å¼: {"observation.state": torch.Tensor(cuda), "observation.images": [torch.Tensor(cuda), ...]}

# 3. æ·»åŠ ä»»åŠ¡æè¿° (å¦‚æœæ˜¯VLAæ¨¡å‹)
if "task" in request:
    policy_obs["task"] = [request["task"]]

# 4. æ¨ç†
with torch.no_grad():
    action = policy.select_action(policy_obs)
# æ ¼å¼: torch.Tensor(cuda), shape: (1, action_dim)

# 5. åºåˆ—åŒ–åŠ¨ä½œ
action_bytes = serialize_tensor(action)

# 6. å‘é€å“åº”
response = {
    "action": action_bytes,
    "status": "success",
    "inference_time_ms": 85.3
}
socket.send(pickle.dumps(response))
```

## ğŸ“ æ•°æ®å¤§å°ä¼°ç®—

### å…¸å‹SO100æœºå™¨äººç¤ºä¾‹

**è§‚æµ‹æ•°æ®**:
- `observation.state`: 6ä¸ªfloat32 = 24 bytes
- `observation.images`: 2ä¸ªç›¸æœºï¼Œ224x224 RGB
  - åŸå§‹: 2 Ã— 224 Ã— 224 Ã— 3 Ã— 4 bytes (float32) = 1.2 MB
  - JPEGå‹ç¼©å: ~50-100 KB

**åŠ¨ä½œæ•°æ®**:
- `action`: 6ä¸ªfloat32 = 24 bytes

**æ€»è®¡ (æ¯æ¬¡è¯·æ±‚)**:
- æœªå‹ç¼©: ~1.2 MB
- å‹ç¼©å›¾åƒ: ~50-100 KB

## âš¡ ä¼˜åŒ–å»ºè®®

### 1. å›¾åƒå‹ç¼©

```python
import cv2

def compress_image(img_tensor: torch.Tensor, quality: int = 85) -> bytes:
    """å‹ç¼©å›¾åƒå‡å°‘ä¼ è¾“é‡"""
    # tensor (C, H, W) -> numpy (H, W, C)
    img_np = (img_tensor.permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)
    
    # JPEGå‹ç¼©
    _, buffer = cv2.imencode('.jpg', img_np, [cv2.IMWRITE_JPEG_QUALITY, quality])
    return buffer.tobytes()

def decompress_image(img_bytes: bytes) -> torch.Tensor:
    """è§£å‹å›¾åƒ"""
    img_np = cv2.imdecode(np.frombuffer(img_bytes, np.uint8), cv2.IMREAD_COLOR)
    img_tensor = torch.from_numpy(img_np).permute(2, 0, 1).float() / 255.0
    return img_tensor
```

### 2. é™ä½åˆ†è¾¨ç‡

```python
import torch.nn.functional as F

def downsample_image(img: torch.Tensor, target_size: tuple = (224, 224)) -> torch.Tensor:
    """é™ä½å›¾åƒåˆ†è¾¨ç‡"""
    return F.interpolate(img.unsqueeze(0), size=target_size, mode='bilinear', align_corners=False).squeeze(0)
```

### 3. åªåœ¨å˜åŒ–æ—¶å‘é€å›¾åƒ

```python
class SmartImageSender:
    def __init__(self, send_every_n_frames: int = 5):
        self.send_every_n = send_every_n_frames
        self.frame_count = 0
        self.last_images = None
    
    def should_send_images(self) -> bool:
        self.frame_count += 1
        return self.frame_count % self.send_every_n == 0
    
    def prepare_observation(self, obs: dict) -> dict:
        if self.should_send_images():
            return obs  # å‘é€å®Œæ•´è§‚æµ‹
        else:
            # åªå‘é€çŠ¶æ€ï¼Œä¸å‘é€å›¾åƒ
            return {"observation.state": obs["observation.state"]}
```

## ğŸ” è°ƒè¯•æŠ€å·§

### æ£€æŸ¥æ•°æ®æ ¼å¼

```python
def check_observation_format(obs: dict) -> None:
    """éªŒè¯è§‚æµ‹æ ¼å¼æ˜¯å¦æ­£ç¡®"""
    print("Observation keys:", obs.keys())
    
    if "observation.state" in obs:
        state = obs["observation.state"]
        print(f"  observation.state: shape={state.shape}, dtype={state.dtype}, device={state.device}")
        assert state.ndim == 2, "stateåº”è¯¥æ˜¯2D: (batch_size, state_dim)"
        assert state.dtype == torch.float32, "stateåº”è¯¥æ˜¯float32"
    
    if "observation.images" in obs:
        images = obs["observation.images"]
        print(f"  observation.images: {len(images)} cameras")
        for i, img in enumerate(images):
            print(f"    camera {i}: shape={img.shape}, dtype={img.dtype}, device={img.device}")
            assert img.ndim == 4, "imageåº”è¯¥æ˜¯4D: (batch_size, C, H, W)"
            assert img.dtype == torch.float32, "imageåº”è¯¥æ˜¯float32"
            assert 0 <= img.min() <= img.max() <= 1, "imageåº”è¯¥åœ¨[0,1]èŒƒå›´å†…"

def check_action_format(action: torch.Tensor) -> None:
    """éªŒè¯åŠ¨ä½œæ ¼å¼æ˜¯å¦æ­£ç¡®"""
    print(f"Action: shape={action.shape}, dtype={action.dtype}, device={action.device}")
    assert action.ndim == 2, "actionåº”è¯¥æ˜¯2D: (batch_size, action_dim)"
    assert action.dtype == torch.float32, "actionåº”è¯¥æ˜¯float32"
```

## ğŸ“ æ€»ç»“

**å…³é”®è¦ç‚¹**:

1. âœ… **ä½¿ç”¨LeRobotæ ‡å‡†é”®å**: `observation.state`, `observation.images`, `action`
2. âœ… **æ­£ç¡®çš„tensorå½¢çŠ¶**: åŒ…å«batchç»´åº¦ï¼Œå›¾åƒæ˜¯channel-first
3. âœ… **æ­£ç¡®çš„æ•°æ®ç±»å‹**: float32ï¼Œå›¾åƒå½’ä¸€åŒ–åˆ°[0,1]
4. âœ… **åºåˆ—åŒ–ä¼ è¾“**: ä½¿ç”¨torch.saveæˆ–numpyåºåˆ—åŒ–
5. âœ… **è®¾å¤‡ç®¡ç†**: å®¢æˆ·ç«¯CPUï¼ŒæœåŠ¡å™¨GPU
6. âœ… **å‹ç¼©ä¼˜åŒ–**: JPEGå‹ç¼©å›¾åƒå‡å°‘å¸¦å®½

éµå¾ªè¿™äº›è§„èŒƒï¼Œä½ çš„è¿œç¨‹æ¨ç†ç³»ç»Ÿå°†å®Œå…¨å…¼å®¹LeRobotç”Ÿæ€ç³»ç»Ÿï¼


